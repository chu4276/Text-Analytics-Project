{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read keyline extracted\n",
    "import pandas as pd\n",
    "import re\n",
    "tagset = pd.read_csv(\"Output/df_keyline_prison.csv\")\n",
    "text = ' '.join(str(x) for x in tagset['Line'])\n",
    "sentences = re.split(r' *[\\.\\?!][\\'\"\\)\\]]* *', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score Compound</th>\n",
       "      <th>Score Negative</th>\n",
       "      <th>Score Neutral</th>\n",
       "      <th>Score Positive</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>jasmine and stars  \f",
       "islamic civilization  mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ernst and bruce b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>lawrence editors  \f",
       "j  fat e m e h k es h ava r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>indd 3  chapel hill  83006 110211 am  \f",
       " 2007 t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.7184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>my good friends minoo riahysharifan orange cou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score Compound  Score Negative  Score Neutral  Score Positive  \\\n",
       "0          0.0000             0.0           1.00            0.00   \n",
       "1          0.0000             0.0           1.00            0.00   \n",
       "2          0.0000             0.0           1.00            0.00   \n",
       "3          0.0000             0.0           1.00            0.00   \n",
       "4          0.7184             0.0           0.75            0.25   \n",
       "\n",
       "                                            Sentence  \n",
       "0  \n",
       "jasmine and stars  \n",
       "islamic civilization  mus...  \n",
       "1                                  ernst and bruce b  \n",
       "2  lawrence editors  \n",
       "j  fat e m e h k es h ava r...  \n",
       "3  indd 3  chapel hill  83006 110211 am  \n",
       " 2007 t...  \n",
       "4  my good friends minoo riahysharifan orange cou...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import re\n",
    "sa = SentimentIntensityAnalyzer()\n",
    "sent_output = []\n",
    "for doc in sentences:\n",
    "    scores = sa.polarity_scores(doc)\n",
    "    output = [scores['compound'],scores['neg'],scores['neu'],scores['pos'],doc]\n",
    "    sent_output.append(output)\n",
    "    \n",
    "df = pd.DataFrame(sent_output, columns =['Score Compound', \n",
    "                                         'Score Negative','Score Neutral','Score Positive','Sentence']) \n",
    "df['Sentence'] = df['Sentence'].str.replace(r'[^\\w\\s]+', '')\n",
    "df.to_csv(\"SA Model/df_Vader.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 positive sentences are:        Score Compound  Score Negative  Score Neutral  Score Positive  \\\n",
      "12417          0.9903           0.000          0.503           0.497   \n",
      "13393          0.9850           0.000          0.626           0.374   \n",
      "15834          0.9847           0.000          0.716           0.284   \n",
      "14400          0.9795           0.037          0.615           0.348   \n",
      "14431          0.9765           0.000          0.590           0.410   \n",
      "21225          0.9719           0.000          0.500           0.500   \n",
      "6959           0.9691           0.008          0.816           0.175   \n",
      "14141          0.9689           0.000          0.772           0.228   \n",
      "5574           0.9676           0.113          0.500           0.387   \n",
      "6319           0.9666           0.049          0.634           0.317   \n",
      "\n",
      "                                                Sentence  \n",
      "12417  but i have grown wiser and more appreciative n...  \n",
      "13393  many years ago my mother asked me if i knew wh...  \n",
      "15834  isbn 9781414371207 hardcover isbn 978141438304...  \n",
      "14400   one can see why babbitt would be both attract...  \n",
      "14431  but of course there are all different kinds of...  \n",
      "21225  but my heart was so filled with love and our s...  \n",
      "6959   for their affection support and the magic of t...  \n",
      "14141  each one of us was honored with a special role...  \n",
      "5574   but it is also about wealth its great attracti...  \n",
      "6319   cent warriors gained  ready to give her  rudab...  \n",
      "The top 10 negative sentences are:        Score Compound  Score Negative  Score Neutral  Score Positive  \\\n",
      "1524          -0.9869           0.484          0.455           0.061   \n",
      "7086          -0.9833           0.408          0.592           0.000   \n",
      "20373         -0.9826           0.240          0.699           0.062   \n",
      "14120         -0.9816           0.366          0.605           0.029   \n",
      "21435         -0.9801           0.388          0.562           0.050   \n",
      "4269          -0.9738           0.400          0.566           0.034   \n",
      "20965         -0.9738           0.288          0.712           0.000   \n",
      "4213          -0.9733           0.330          0.562           0.108   \n",
      "7536          -0.9727           0.280          0.701           0.019   \n",
      "9254          -0.9724           0.538          0.462           0.000   \n",
      "\n",
      "                                                Sentence  \n",
      "1524   but then others who witness my death or hear a...  \n",
      "7086   she was scared of the snow and disease and lon...  \n",
      "20373  4  kobra the gaze of death  120  roudabeh dece...  \n",
      "14120  as they navigate observing the lonesomeness of...  \n",
      "21435  did he starve to death or die from lack of wat...  \n",
      "4269   the isis chroniclers remained obsessed with re...  \n",
      "20965  the torturers were taking turns but he was bei...  \n",
      "4213   the argument in response often went like this ...  \n",
      "7536   there was no denying prerevolution corruption ...  \n",
      "9254    this is a problem not just for the uneducated...  \n"
     ]
    }
   ],
   "source": [
    "# list top 10 positive sentences\n",
    "top_10_pos = df.nlargest(10, 'Score Compound')\n",
    "top_10_pos.to_csv('SA Model/Top_Pos_Vader.csv', index=False)\n",
    "# list top 10 negative sentences\n",
    "top_10_neg = df.nsmallest(10, 'Score Compound')\n",
    "top_10_neg.to_csv('SA Model/Top_Neg_Vader.csv', index=False)\n",
    "print(\"The top 10 positive sentences are:\", top_10_pos)\n",
    "print(\"The top 10 negative sentences are:\", top_10_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Documentation Source](https://stackabuse.com/sentiment-analysis-in-python-with-textblob/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob’s output for a polarity task is a float within the range [-1.0, 1.0] where -1.0 is a negative polarity and 1.0 is positive. This score can also be equal to 0, which stands for a neutral evaluation of a statement as it doesn’t contain any words from the training set.\n",
    "\n",
    "Whereas, a subjectivity/objectivity identification task reports a float within the range [0.0, 1.0] where 0.0 is a very objective sentence and 1.0 is very subjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>jasmine and stars  \f",
       "islamic civilization  mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ernst and bruce b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>lawrence editors  \f",
       "j  fat e m e h k es h ava r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>indd 3  chapel hill  83006 110211 am  \f",
       " 2007 t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.418182</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>my good friends minoo riahysharifan orange cou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Polarity  Subjectivity                                           Sentence\n",
       "0  0.000000      0.000000  \n",
       "jasmine and stars  \n",
       "islamic civilization  mus...\n",
       "1  0.000000      0.000000                                  ernst and bruce b\n",
       "2  0.500000      0.500000  lawrence editors  \n",
       "j  fat e m e h k es h ava r...\n",
       "3  0.000000      0.000000  indd 3  chapel hill  83006 110211 am  \n",
       " 2007 t...\n",
       "4  0.418182      0.527273  my good friends minoo riahysharifan orange cou..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "import re\n",
    "# Preparing an input sentence\n",
    "sentence = '''The platform provides universal access to the world's best education, partnering with top universities and organizations to offer courses online.'''\n",
    "sent_output = []\n",
    "for doc in sentences:\n",
    "    analysisPol = TextBlob(doc).polarity\n",
    "    analysisSub = TextBlob(doc).subjectivity\n",
    "    output = [analysisPol,analysisSub,doc]\n",
    "    sent_output.append(output)\n",
    "       \n",
    "df = pd.DataFrame(sent_output, columns =['Polarity','Subjectivity','Sentence']) \n",
    "df['Sentence'] = df['Sentence'].str.replace(r'[^\\w\\s]+', '')\n",
    "df.to_csv(\"SA Model/df_TextBlob.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 positive sentences are:       Polarity  Subjectivity  \\\n",
      "279        1.0           1.0   \n",
      "798        1.0           1.0   \n",
      "2297       1.0           0.3   \n",
      "2886       1.0           0.3   \n",
      "3331       1.0           0.3   \n",
      "4028       1.0           1.0   \n",
      "6276       1.0           0.3   \n",
      "6355       1.0           1.0   \n",
      "6626       1.0           1.0   \n",
      "7342       1.0           1.0   \n",
      "\n",
      "                                               Sentence  \n",
      "279   she has always seemed perfect serving others h...  \n",
      "798   he read them with authority as if they were hi...  \n",
      "2297  i gave the best speech of my life there in tha...  \n",
      "2886  maryam lived in one of the best an octagonal b...  \n",
      "3331  60 farzanehs exceedingly unbiased viewpoint ma...  \n",
      "4028  walid had listened to their arguments as a tee...  \n",
      "6276  after school we were taken minas house where l...  \n",
      "6355  being i  ate  to hear her talk it would seem m...  \n",
      "6626  the prosecu  of my father with his greatest de...  \n",
      "7342   azarmis voice could be heard god bless this w...  \n",
      "The top 10 negative sentences are:       Polarity  Subjectivity  \\\n",
      "229       -1.0           1.0   \n",
      "267       -1.0           1.0   \n",
      "410       -1.0           1.0   \n",
      "429       -1.0           1.0   \n",
      "456       -1.0           1.0   \n",
      "816       -1.0           1.0   \n",
      "1267      -1.0           1.0   \n",
      "1298      -1.0           1.0   \n",
      "2287      -1.0           1.0   \n",
      "2330      -1.0           1.0   \n",
      "\n",
      "                                               Sentence  \n",
      "229   in this case ignorance is not the worst proble...  \n",
      "267   farrukhlaqa asks why if this woman is insane h...  \n",
      "410                        we are in a war against evil  \n",
      "429   the records of that terrible war are not class...  \n",
      "456      i drove people insane with questions i am told  \n",
      "816   something terrible is happening in this countr...  \n",
      "1267  we have to protect islam gods law and gods peo...  \n",
      "1298  i had tried to accept my situation and to unde...  \n",
      "2287          youve been up for two days this is insane  \n",
      "2330  at the ceremony the scent of jasmine casablanc...  \n"
     ]
    }
   ],
   "source": [
    "# list top 10 positive sentences\n",
    "top_10_pos = df.nlargest(10, 'Polarity')\n",
    "top_10_pos.to_csv('SA Model/Top_Pos_Textblob.csv', index=False)\n",
    "# list top 10 negative sentences\n",
    "top_10_neg = df.nsmallest(10, 'Polarity')\n",
    "top_10_neg.to_csv('SA Model/Top_Neg_Textlob.csv', index=False)\n",
    "print(\"The top 10 positive sentences are:\", top_10_pos)\n",
    "print(\"The top 10 negative sentences are:\", top_10_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Documentation Source](https://huggingface.co/transformers/quicktour.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Collecting sacremoses (from transformers)\n",
      "  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "Collecting protobuf (from transformers)\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/f4/089025cfa3ee62f89cae73f4d36daf46f339c6df61becfe4b24f3aeb3c0d/protobuf-3.14.0-cp37-cp37m-win_amd64.whl (798kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (4.50.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (19.2)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (1.19.1)\n",
      "Collecting tokenizers==0.9.3 (from transformers)\n",
      "  Downloading https://files.pythonhosted.org/packages/c4/eb/7391faa9651b568a233379d93e0754d4fc94498191e23d77d9ab8274a3e7/tokenizers-0.9.3-cp37-cp37m-win_amd64.whl (1.9MB)\n",
      "Collecting sentencepiece==0.1.91 (from transformers)\n",
      "  Downloading https://files.pythonhosted.org/packages/78/c7/fb817b7f0e8a4df1b1973a8a66c4db6fe10794a679cb3f39cd27cd1e182c/sentencepiece-0.1.91-cp37-cp37m-win_amd64.whl (1.2MB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (2020.7.14)\n",
      "Requirement already satisfied: six in c:\\users\\asus\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\asus\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (0.13.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from packaging->transformers) (2.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py): started\n",
      "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=00b9f074f09f8812860e3c2fa0fdf8eec9346b64cdffa2dac96c9c6fb50e839b\n",
      "  Stored in directory: C:\\Users\\asus\\AppData\\Local\\pip\\Cache\\wheels\\29\\3c\\fd\\7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, protobuf, tokenizers, sentencepiece, transformers\n",
      "Successfully installed protobuf-3.14.0 sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ab0d6b610747>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sentiment-analysis'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'We are very happy to show you the 🤗 Transformers library.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "classifier('We are very happy to show you the 🤗 Transformers library.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> results = classifier([\"We are very happy to show you the 🤗 Transformers library.\",\n",
    "...            \"We hope you don't hate it.\"])\n",
    ">>> for result in results:\n",
    "...     print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\n",
    "label: POSITIVE, with score: 0.9998\n",
    "label: NEGATIVE, with score: 0.5309"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
